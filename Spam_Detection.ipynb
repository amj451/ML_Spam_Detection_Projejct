{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "444a9752-e61a-46c5-b70f-f1d16bbe02a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.30%\n",
      "Confusion Matrix:\n",
      " [[965   1]\n",
      " [ 18 131]]\n",
      "Testing Model ...\n",
      "job oppurtunity in WIPRO\n",
      "Ham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohammed Amjad\n",
      "[nltk_data]     Ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Use TF-IDF for better weighting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report \n",
    "from nltk.corpus import stopwords\n",
    "import joblib\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('mail_data.csv', encoding='latin-1')\n",
    "data = data[['Category', 'Message']]\n",
    "data.columns = ['Category', 'Message']\n",
    "data['Category'] = data['Category'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# Preprocess text (consider stemming/lemmatization)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Consider stemming or lemmatization for better normalization (optional)\n",
    "    # from nltk.stem import PorterStemmer\n",
    "    # stemmer = PorterStemmer()\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['Message'] = data['Message'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction (try TF-IDF)\n",
    "vectorizer = TfidfVectorizer(max_features=2000)  # Reduce features for efficiency (consider tuning)\n",
    "X = vectorizer.fit_transform(data['Message'])\n",
    "y = data['Category']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model (consider GridSearchCV for hyperparameter tuning)\n",
    "model = MultinomialNB()\n",
    "# You can try GridSearchCV to find optimal hyperparameters like alpha:\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "# grid = GridSearchCV(MultinomialNB(), param_grid=param_grid, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "# model = grid.best_estimator_\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# class_report = classification_report(y_test, y_pred) Â  \n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "# print('Classification Report:\\n', class_report)\n",
    "\n",
    "# Test model with a new email\n",
    "def predict_email(text):\n",
    "    text = preprocess_text(text)\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    prediction = model.predict(text_vector)\n",
    "    return 'Spam' if prediction[0] == 1 else 'Ham'\n",
    "\n",
    "print('Testing Model ...')\n",
    "\n",
    "email = \"job oppurtunity in WIPRO\"\n",
    "print(email)\n",
    "\n",
    "print(predict_email(email))\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(model, 'spam_model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "\n",
    "\n",
    "# old code \n",
    "\n",
    "# import pandas as pd\n",
    "# import nltk\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# from nltk.corpus import stopwords\n",
    "# import joblib\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# # Load dataset\n",
    "# data = pd.read_csv('mail_data.csv', encoding='latin-1')\n",
    "# data = data[['Category', 'Message']]\n",
    "# data.columns = ['Category', 'Message']\n",
    "# data['Category'] = data['Category'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# # Preprocess text\n",
    "# def preprocess_text(text):\n",
    "#     text = text.lower()\n",
    "#     words = text.split()\n",
    "#     words = [word for word in words if word not in stop_words]\n",
    "#     return ' '.join(words)\n",
    "\n",
    "# data['Message'] = data['Message'].apply(preprocess_text)\n",
    "\n",
    "# # Feature extraction\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(data['Message'])\n",
    "# y = data['Message']\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train model\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate model\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "# # print('Confusion Matrix:\\n', conf_matrix)\n",
    "# # print('Classification Report:\\n', class_report)\n",
    "\n",
    "# # Test model with a new email\n",
    "# def predict_email(text):\n",
    "#     text = preprocess_text(text)\n",
    "#     text_vector = vectorizer.transform([text])\n",
    "#     prediction = model.predict(text_vector)\n",
    "#     return 'Spam' if prediction[0] == 1 else 'Ham'\n",
    "\n",
    "# print('Testing Model ...')\n",
    "\n",
    "# email = \"Last Chance! Exclusive Deal Just for You\"\n",
    "# print(email)\n",
    "\n",
    "# print(predict_email(email))\n",
    "\n",
    "# # Save model and vectorizer\n",
    "# joblib.dump(model, 'spam_model.pkl')\n",
    "# joblib.dump(vectorizer, 'vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f6157-59a4-4d6a-a88f-75b600115719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
